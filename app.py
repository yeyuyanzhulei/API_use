import streamlit as st
from openai import OpenAI
# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="æ™ºèƒ½å¯¹è¯åŠ©æ‰‹", page_icon="ğŸ’¬", layout="wide")
st.title("æ™ºèƒ½å¯¹è¯åŠ©æ‰‹ ğŸ’¬")

# --- [Chrome ä¸“ç”¨ä¿®å¤] CSS æ ·å¼ ---
# overflow-anchor: none; æ˜¯è§£å†³ Chrome æ»šåŠ¨é”æ­»çš„å…³é”®
st.markdown("""
    <style>
        /* 1. å¼ºåˆ¶ä¸»å®¹å™¨å…è®¸å‚ç›´æ»šåŠ¨ï¼Œç»å¯¹ä¸è¦éšè—æ»šåŠ¨æ¡ */
        [data-testid="stAppViewContainer"] {
            overflow-y: auto !important; /* å¼ºåˆ¶å¼€å¯æ»šåŠ¨ */
            overflow-x: hidden !important;
            height: 100vh; /* ç¡®ä¿å æ»¡è§†çª—é«˜åº¦ */
        }
        
        /* 2. è‡ªå®šä¹‰æ»šåŠ¨æ¡æ ·å¼ (å¯é€‰ï¼Œä¸ºäº†è®©å®ƒæ›´æ˜æ˜¾) */
        ::-webkit-scrollbar {
            width: 10px;
            background: transparent;
        }
        ::-webkit-scrollbar-thumb {
            background: #888; 
            border-radius: 5px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #555; 
        }

        /* 3. ç»™æœ€åä¸€æ¡æ¶ˆæ¯åº•éƒ¨å¢åŠ å¤§é‡ç•™ç™½ */
        /* è¿™æ · scrollIntoView æ—¶ï¼Œæ–‡å­—ä¼šè¢«æ¨åˆ°è¾“å…¥æ¡†ä¸Šæ–¹ï¼Œè€Œä¸æ˜¯è¢«è¾“å…¥æ¡†ç›–ä½ */
        .stChatMessage:last-child {
            padding-bottom: 150px; 
        }
    </style>
""", unsafe_allow_html=True)

# 2. ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.markdown("### å‚æ•°è®¾ç½®")
    # è¿™é‡Œçš„keyé»˜è®¤ä¸ºç©ºï¼Œä½ å¯ä»¥å¡«å…¥ä½ çš„key
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
        st.success("âœ… å·²æ£€æµ‹åˆ°äº‘ç«¯é…ç½®çš„ API Key")
    else:
        api_key = st.text_input("OpenAI API Key", type="password")
    
    # å¦‚æœä½ ä½¿ç”¨å®˜æ–¹ APIï¼Œbase_url ä¸éœ€è¦æ”¹ã€‚
    # å¦‚æœä½ ä½¿ç”¨ä¸­è½¬æœåŠ¡ (å¦‚ OhMyGPT, DeepSeek ç­‰)ï¼Œè¯·ä¿®æ”¹è¿™é‡Œã€‚
    if "BASE_URL" in st.secrets:
        base_url = st.secrets["BASE_URL"]
        st.success("âœ… å·²æ£€æµ‹åˆ°äº‘ç«¯é…ç½®çš„ Base URL")
    else:
        base_url = st.text_input("Base URL (å¯é€‰)", value="https://api.deepseek.com")
    
    st.markdown("---")
    # å¢åŠ ä¸€ä¸ªæ¸…ç©ºå†å²çš„æŒ‰é’®ï¼Œæ–¹ä¾¿æµ‹è¯•
    if st.button("æ¸…ç©ºå†å²è®°å½•"):
        st.session_state.messages = []
        st.rerun()
        
# 3. åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
# åªæœ‰å½“ç”¨æˆ·è¾“å…¥äº† Key æ‰åˆå§‹åŒ–ï¼Œå¦åˆ™åç»­ä¼šæŠ¥é”™
if api_key:
    client = OpenAI(api_key=api_key, base_url=base_url)
else:
    # å¦‚æœæ²¡å¡«Keyï¼Œç»™ä¸ªæç¤ºå¹¶åœæ­¢è¿è¡Œåç»­ä»£ç 
    st.warning("API é”™è¯¯ï¼ï¼ï¼")
    st.stop()
    
# 4. åˆå§‹åŒ–
if "messages" not in st.session_state:
    # å¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸€ä¸ªç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰ AI çš„äººè®¾
    st.session_state.messages = [
        {"role": "system", "content":"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹"}
    ]

# 5. æ¸²æŸ“å†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    # å‡å¦‚æ˜¯ system æ¶ˆæ¯ï¼Œæˆ‘ä»¬é€šå¸¸ä¸åœ¨ç•Œé¢æ˜¾ç¤º
    if msg["role"] == "system":
        continue
    
    with st.chat_message(msg["role"]):
        st.write(msg["content"]) 
        
# 6. å¤„ç†è¾“å…¥ä¸è°ƒç”¨API

if prompt := st.chat_input("æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ"):
    # A. ç”¨æˆ·å‘æ¶ˆæ¯
    # 1. å­˜å…¥å†å²
    st.session_state.messages.append({"role":"user", "content": prompt})
    # 2.ç•Œé¢æ˜¾ç¤º
    with st.chat_message("user"):
        st.write(prompt)
        
    # B. AI å›å¤
    # 1. ç•Œé¢æ˜¾ç¤ºä¸€ä¸ªâ€œæ€è€ƒä¸­â€çš„çŠ¶æ€
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # å…³é”®æ­¥éª¤ï¼šè°ƒç”¨ API
            # æ³¨æ„ï¼šæˆ‘ä»¬å°†st.session_state.messagesï¼ˆæ•´ä¸ªå†å²ï¼‰ä¼ ç»™äº†API
            # è¿™å°±æ˜¯â€œè®°å¿†â€çš„æ¥æºï¼
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=st.session_state.messages,
                temperature=0.7,
                stream=True,
            )
            # ai_content = response.choices[0].message.content
            # message_placeholder.markdown(ai_content)
            # å¾ªç¯å¤„ç†æ•°æ®æµ
            for chunck in response:
                # æ£€æŸ¥è¿™ä¸ªæ•°æ®å—é‡Œæœ‰æ²¡æœ‰å†…å®¹
                if chunck.choices[0].delta.content is not None:
                    # è·å–è¿™ä¸€å°å—æ–‡æœ¬
                    content = chunck.choices[0].delta.content
                    # æ‹¼æ¥åˆ°æ€»å›å¤ä¸­
                    full_response += content
                    # å®æ—¶æ›´æ–°ç•Œé¢æ˜¾ç¤º,åŠ ä¸€ä¸ªå…‰æ ‡æ¨¡æ‹Ÿæ‰“å­—æ„Ÿ
                    message_placeholder.markdown(full_response + "â–Œ")
            # æœ€åæŠŠå®Œæ•´å›å¤æ˜¾ç¤ºå‡ºæ¥ï¼Œå»æ‰å…‰æ ‡
            message_placeholder.markdown(full_response)
                
            # 2. æŠŠ AI å›å¤å­˜å…¥å†å²
            st.session_state.messages.append({"role":"assistant", "content": full_response})

        except Exception as e:
            message_placeholder.markdown(f"å‡ºé”™äº†: {e}")
            
            
            




